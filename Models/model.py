# -*- coding: utf-8 -*-
"""Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1txPei7Fg90-PTcBWAhNcdRQLq937p9uy
"""

import tensorflow as tf
import os
import numpy as np
import csv
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.dates import DateFormatter
import math
import statsmodels.api as sm
from numpy import *
from math import sqrt
from pandas import *
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
from pickle import dump

from numpy import *
from math import sqrt
from pandas import *
from datetime import datetime, timedelta

from sklearn.model_selection import KFold

from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import mean_squared_error

from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Dropout, Bidirectional, Concatenate, Input, Lambda, Multiply, Add
from tensorflow.keras.layers import BatchNormalization, Embedding, TimeDistributed, LeakyReLU
from tensorflow.keras.layers import LSTM, GRU
from tensorflow.keras.optimizers import Adam

import seaborn as sns

from matplotlib import pyplot
from pickle import load

from google.colab import drive
drive.mount('/content/drive')

allmodal = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Crypto_prediction/allmodal.csv',parse_dates=['time'])
allmodal

allmodal.corr()

dataplot = sns.heatmap(allmodal.corr(), cmap="YlGnBu", annot=True)

# displaying heatmap
plt.show()

allmodal = allmodal.set_index('time')
allmodal.index = pd.to_datetime(allmodal.index)

"""Change the data to stationary one"""

allmodal = allmodal.diff().dropna()

# Split the data into financial and sentiment data
financial_data = allmodal[['high', 'low', 'open', 'volumefrom', 'volumeto', 'close']]
sentiment_data = allmodal[['news', 'Media']]

# Common preprocessing steps
def preprocess_data(data):
    nrows = data.shape[0]
    np_data_unscaled = np.array(data)
    np_data = np.reshape(np_data_unscaled, (nrows, -1))

    # Scaling
    scaler = MinMaxScaler()
    np_data_scaled = scaler.fit_transform(np_data_unscaled)
    return np_data_scaled

np_financial_scaled = preprocess_data(financial_data)
np_sentiment_scaled = preprocess_data(sentiment_data)

# Creating a separate scaler for scaling predictions
scaler_pred = MinMaxScaler()
df_Close = pd.DataFrame(financial_data['close'])
np_Close_scaled = scaler_pred.fit_transform(df_Close)

# Set the sequence length
sequence_length = 14

# Prediction Index
index_Close = financial_data.columns.get_loc("close")

# Split the training data into train, test and validation datasets
train_data_len = math.ceil(np_financial_scaled.shape[0] * 0.7)
val_data_len = math.ceil(np_financial_scaled.shape[0] * 0.2)
train_financial = np_financial_scaled[0:train_data_len, :]
test_financial = np_financial_scaled[train_data_len:train_data_len+val_data_len, :]
val_financial = np_financial_scaled[train_data_len+val_data_len:, :]

train_sentiment = np_sentiment_scaled[0:train_data_len, :]
test_sentiment = np_sentiment_scaled[train_data_len:train_data_len+val_data_len, :]
val_sentiment = np_sentiment_scaled[train_data_len+val_data_len:, :]

# Partition the dataset
def partition_dataset(sequence_length, input_data, target_data, target_column_index):
    x, y = [], []
    data_len = input_data.shape[0]
    for i in range(sequence_length, data_len):
        x.append(input_data[i-sequence_length:i,:])
        y.append(target_data[i, target_column_index])
    return np.array(x), np.array(y)

x_train_financial, y_train_financial = partition_dataset(sequence_length, train_financial, train_financial, index_Close)
x_test_financial, y_test_financial = partition_dataset(sequence_length, test_financial, test_financial, index_Close)
x_val_financial, y_val_financial = partition_dataset(sequence_length, val_financial, val_financial, index_Close)

# For sentiment data, input is from sentiment_data, but the target (y) is from the corresponding rows of financial_data
x_train_sentiment, y_train_sentiment = partition_dataset(sequence_length, train_sentiment, train_financial, index_Close)
x_test_sentiment, y_test_sentiment = partition_dataset(sequence_length, test_sentiment, test_financial, index_Close)
x_val_sentiment, y_val_sentiment = partition_dataset(sequence_length, val_sentiment, val_financial, index_Close)

# Print shapes
print(x_train_financial.shape, y_train_financial.shape)
print(x_test_financial.shape, y_test_financial.shape)
print(x_val_financial.shape, y_val_financial.shape)

print(x_train_sentiment.shape, y_train_sentiment.shape)
print(x_test_sentiment.shape, y_test_sentiment.shape)
print(x_val_sentiment.shape, y_val_sentiment.shape)

# Validate that the prediction value and the input match up
print(x_train_financial[1][sequence_length-1][index_Close])
print(y_train_financial[0])

from keras.layers import Layer, Dense, Dot, Softmax
import keras.backend as K

class ScaledDotProductAttention(Layer):
    def __init__(self, **kwargs):
        super(ScaledDotProductAttention, self).__init__(**kwargs)

    def build(self, input_shape):
        # Create a trainable weight variable for Q, K, V transformations
        self.W_Q = self.add_weight(name='W_Q',
                                   shape=(input_shape[-1], input_shape[-1]),
                                   initializer='uniform',
                                   trainable=True)
        self.W_K = self.add_weight(name='W_K',
                                   shape=(input_shape[-1], input_shape[-1]),
                                   initializer='uniform',
                                   trainable=True)
        self.W_V = self.add_weight(name='W_V',
                                   shape=(input_shape[-1], input_shape[-1]),
                                   initializer='uniform',
                                   trainable=True)
        super(ScaledDotProductAttention, self).build(input_shape)

    def call(self, x):
        Q = K.dot(x, self.W_Q)
        K_mat = K.dot(x, self.W_K)
        V = K.dot(x, self.W_V)

        # Scaled dot product between Q and K
        attn_score = Dot(axes=[2, 2])([Q, K_mat])  # Calculate dot product
        attn_score = attn_score / K.sqrt(K.cast(K.shape(K_mat)[-1], 'float32'))  # Scale the dot product
        attn_weights = Softmax(axis=-1)(attn_score)  # Apply softmax to get the weights

        # Multiply attention weights with V to get the output
        output = Dot(axes=[2, 1])([attn_weights, V])
        return output

    def compute_output_shape(self, input_shape):
        return input_shape

# Example usage:
from keras.models import Model
from keras.layers import Input

financial_input = Input(shape=(sequence_length, financial_data.shape[1]))
new_financial_input = ScaledDotProductAttention()(financial_input)

sentiment_input = Input(shape=(sequence_length, sentiment_data.shape[1]))
new_sentiment_input = ScaledDotProductAttention()(sentiment_input)

# You can now use 'new_financial_input' and 'new_sentiment_input' as inputs for further processing.

from keras.layers import Concatenate

class CrossModalAttention(Layer):
    def __init__(self, **kwargs):
        super(CrossModalAttention, self).__init__(**kwargs)

    def build(self, input_shape):
        # For modality 1 attending to modality 2
        self.W_Q1 = self.add_weight(name='W_Q1',
                                   shape=(input_shape[0][-1], input_shape[0][-1]),
                                   initializer='uniform',
                                   trainable=True)
        self.W_K1 = self.add_weight(name='W_K1',
                                   shape=(input_shape[1][-1], input_shape[0][-1]),
                                   initializer='uniform',
                                   trainable=True)
        self.W_V1 = self.add_weight(name='W_V1',
                                   shape=(input_shape[1][-1], input_shape[1][-1]),
                                   initializer='uniform',
                                   trainable=True)

        # For modality 2 attending to modality 1
        self.W_Q2 = self.add_weight(name='W_Q2',
                                   shape=(input_shape[1][-1], input_shape[1][-1]),
                                   initializer='uniform',
                                   trainable=True)
        self.W_K2 = self.add_weight(name='W_K2',
                                   shape=(input_shape[0][-1], input_shape[1][-1]),
                                   initializer='uniform',
                                   trainable=True)
        self.W_V2 = self.add_weight(name='W_V2',
                                   shape=(input_shape[0][-1], input_shape[0][-1]),
                                   initializer='uniform',
                                   trainable=True)
        super(CrossModalAttention, self).build(input_shape)

    def call(self, inputs):
        x1, x2 = inputs

        # For modality 1 attending to modality 2
        Q1 = K.dot(x1, self.W_Q1)
        K1 = K.dot(x2, self.W_K1)
        V1 = K.dot(x2, self.W_V1)
        attn_score1 = K.batch_dot(Q1, K.permute_dimensions(K1, (0, 2, 1))) / K.sqrt(K.cast(K.shape(K1)[-1], 'float32'))
        attn_weights1 = K.softmax(attn_score1, axis=-1)
        output1 = K.batch_dot(attn_weights1, V1)

        # For modality 2 attending to modality 1
        Q2 = K.dot(x2, self.W_Q2)
        K2 = K.dot(x1, self.W_K2)
        V2 = K.dot(x1, self.W_V2)
        attn_score2 = K.batch_dot(Q2, K.permute_dimensions(K2, (0, 2, 1))) / K.sqrt(K.cast(K.shape(K2)[-1], 'float32'))
        attn_weights2 = K.softmax(attn_score2, axis=-1)
        output2 = K.batch_dot(attn_weights2, V2)

        # Concatenate the outputs for the two modalities
        fused_output = Concatenate(axis=-1)([output1, output2])

        return fused_output

    def compute_output_shape(self, input_shape):
        return (input_shape[0][0], input_shape[0][1], input_shape[0][-1] + input_shape[1][-1])


    def compute_output_shape(self, input_shape):
        return (input_shape[0][0], input_shape[0][1], input_shape[0][-1] + input_shape[1][-1])

# Define the attention mechanisms
financial_input = Input(shape=(sequence_length, financial_data.shape[1]))
sentiment_input = Input(shape=(sequence_length, sentiment_data.shape[1]))

new_financial_input = ScaledDotProductAttention()(financial_input)
new_sentiment_input = ScaledDotProductAttention()(sentiment_input)
fused_input = CrossModalAttention()([new_financial_input, new_sentiment_input])


# 'fused_input' is now the fused representation of the two modalities, and can be used for further processing.

# Define the LSTM model
n_neurons = 112  # for example, adjust as needed
x = LSTM(n_neurons, return_sequences=True)(fused_input)
x = LSTM(n_neurons, return_sequences=False)(x)
x = Dense(5, activation='relu')(x)  # Adjust activation function if needed
output = Dense(1, activation='linear')(x)  # Linear activation for regression tasks

# Compile the model
model = Model(inputs=[financial_input, sentiment_input], outputs=output)
model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')  # Mean Squared Error for regression tasks

# Print the model summary
model.summary()

# Note: Make sure your training data for both financial and sentiment modalities have the same number of samples
model.fit([x_train_financial, x_train_sentiment], y_train_financial, epochs=100, batch_size=32, validation_data=([x_test_financial, x_test_sentiment], y_test_financial), verbose=1)



"""-----------

"""